<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Semantic-Preserving Hijacking Attacks via Adaptive Greedy Local Search</title>
  <meta name="description" content="We propose Adaptive Greedy Local Search (AGLS), a black-box semantic-preserving attack that hijacks automatic prompt optimization modules in LLMs while keeping BERTScore ≈ 0.80.">
  <meta name="author" content="Chong Zhang, Xiang Li, Jia Wang, Shan Liang, Haochen Xue, Xiaobo Jin">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <style>
    .hero.is-primary { background: linear-gradient(141deg,#1e88e5 0%,#1565c0 100%); }
    .title, .subtitle { color: #fff; }
    pre { background:#f8f9fa; padding:1rem; border-radius:6px; overflow-x:auto; }
  </style>
</head>
<body>

<section class="hero is-primary is-bold">
  <div class="hero-body">
    <div class="container">
      <h1 class="title is-1">Semantic-Preserving Hijacking Attacks via Adaptive Greedy Local Search</h1>
      <h2 class="subtitle is-4">
        Chong Zhang<sup>*</sup>&nbsp;&nbsp; Xiang Li<sup>*</sup>&nbsp;&nbsp; Jia Wang&nbsp;&nbsp; Shan Liang&nbsp;&nbsp; Haochen Xue&nbsp;&nbsp; Xiaobo Jin<sup>†</sup>
      </h2>
      <p class="is-size-5">
        Xi’an Jiaotong-Liverpool University | The Chinese University of Hong Kong | University of Liverpool<br>
        <sup>*</sup>Equal contribution <sup>†</sup>Corresponding author: <a href="mailto:Xiaobo.Jin@xjtlu.edu.cn" style="color:#fff;">Xiaobo.Jin@xjtlu.edu.cn</a>
      </p>
      <div class="buttons is-centered" style="margin-top:2rem;">
        <a href="https://anonymous.4open.science/r/A5E7202F" class="button is-white is-outlined">
          <span class="icon"><i class="fab fa-github"></i></span><span>Code (Anonymous)</span>
        </a>
        <a href="AGLS-ICME.pdf" class="button is-white is-outlined">
          <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper (ICME submission)</span>
        </a>
        <a href="https://openreview.net/forum?id=PpKTeoHBFA" class="button is-white is-outlined">
          <span class="icon"><i class="fas fa-external-link-alt"></i></span><span>ACL ARR 2025 May Reviews</span>
        </a>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <figure class="image">
          <img src="https://i.imgur.com/0Z3jK8v.png" alt="AGLS Overview">
          <figcaption class="has-text-centered"><strong>Fig. 1</strong> – Core idea of Adaptive Greedy Local Search</figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <h2 class="title is-3 has-text-centered">Abstract</h2>
    <div class="content">
      <p>Large Language Models (LLMs) are increasingly equipped with automatic prompt-optimization modules that rewrite the user’s input and explicitly present an “improved” prompt to the user before generating the final response. Although this visibility is designed to enhance trust and user control, the optimizer’s autonomous selection of the single “best” candidate remains fully unconstrained.</p>
      <p>The attacker can hijack the original prompt or the prompt generated by automatic prompt optimization for alternative rewriting, so as to induce semantic drift to complete the hijack optimization process, which greatly affects the response of LLM.</p>
      <p>To systematically expose this risk, we propose <strong>Adaptive Greedy Local Search (AGLS)</strong>, a prompt hijacking attack. This attack injects semantic offset by hijacking the auto-prompt optimization results in a black-box scenario. AGLS dynamically adjusts candidate replacements at linguistic checkpoints to keep BERTScore ≈ 0.80 while maximizing goal discrepancy.</p>
      <p>Extensive experiments on popular and open-source LLMs demonstrate that AGLS achieves higher attack success rates than prior semantic-preserving attacks under strictly comparable similarity budgets. The results highlight the risk of hijacking and tampering with explicit auto-prompting optimizations in user-facing systems.</p>
      <p><strong>Code is available at:</strong> <a href="https://anonymous.4open.science/r/A5E7202F">https://anonymous.4open.science/r/A5E7202F</a></p>
    </div>
  </div>
</section>

<section class="section has-background-light">
  <div class="container">
    <h2 class="title is-3 has-text-centered">Key Contributions</h2>
    <div class="columns is-multiline is-centered">
      <div class="column is-4">
        <div class="box has-text-centered">
          <span class="icon is-large has-text-primary"><i class="fas fa-bullseye fa-3x"></i></span>
          <h4 class="title is-5" style="margin-top:1rem;">First to reveal the attack surface</h4>
          <p>introduced by just-in-time auto-prompt optimization modules widely deployed in production LLMs (Bing Copilot, Gemini, Claude.ai, Perplexity Pro, etc.).</p>
        </div>
      </div>
      <div class="column is-4">
        <div class="box has-text-centered">
          <span class="icon is-large has-text-success"><i class="fas fa-search fa-3x"></i></span>
          <h4 class="title is-5" style="margin-top:1rem;">Adaptive Greedy Local Search (AGLS)</h4>
          <p>Black-box semantic-preserving attack that mimics real optimizer behavior and keeps BERTScore ≈ 0.80 while maximizing intent drift.</p>
        </div>
      </div>
      <div class="column is-4">
        <div class="box has-text-centered">
          <span class="icon is-large has-text-info"><i class="fas fa-chart-line fa-3x"></i></span>
          <h4 class="title is-5" style="margin-top:1rem;">Superior Performance</h4>
          <p>Outperforms TABS, BeamAttack and other baselines under the same similarity budget on >2400 test cases.</p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <h2 class="title is-3 has-text-centered">Method Overview</h2>
    <div class="content">
      <p>AGLS works in three main steps:</p>
      <ol>
        <li><strong>Hierarchical decomposition & checkpoint setting</strong> – Split input into sub-clauses and define linguistic checking points (usually punctuation).</li>
        <li><strong>Masked keyword replacement with Top-k candidates</strong> – At each checking point, mask the current keyword and generate Top-k semantically similar replacements.</li>
        <li><strong>Adaptive rank adjustment</strong> – Dynamically move up/down in the Top-k list (more similar) or down (more divergent) to keep partial BERTScore ≈ 0.80 while maximizing final goal discrepancy.</li>
      </ol>
      <p>This greedy local search with similarity checkpoints successfully hijacks the optimizer’s “best candidate” selection in real systems.</p>
    </div>
  </div>
</section>

<section class="section has-background-light">
  <div class="container">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>@article{zhang2025agls,
  title   = {Semantic-Preserving Hijacking Attacks via Adaptive Greedy Local Search},
  author  = {Chong Zhang and Xiang Li and Jia Wang and Shan Liang and Haochen Xue and Xiaobo Jin},
  year    = {2025},
  note    = {Submitted to ICME 2025 (under review completed at ACL ARR 2025 May )}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="content has-text-centered">
    <p>© 2025 Chong Zhang, Xiang Li, et al. • Built with Bulma</p>
  </div>
</footer>

</body>
</html>
